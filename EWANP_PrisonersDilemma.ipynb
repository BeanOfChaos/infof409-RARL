{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Dynamics and Norm Psychology Supports Human Cooperation in a Large-Scale Prisonerâ€™s Dilemma on Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:12:26.061021Z",
     "start_time": "2019-08-31T14:12:24.938711Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:12:26.072033Z",
     "start_time": "2019-08-31T14:12:26.062024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixed parameters\n",
    "T = 10\n",
    "R = 7\n",
    "P = 0\n",
    "S = 0\n",
    "payoffs = [[R, S],[T, P]] # actions C = 0, D = 1\n",
    "n = 1000       # rounds\n",
    "N = 625        # number of agents\n",
    "k = 4          # number of neighbours\n",
    "D_0 = 0.6      # total drive\n",
    "alpha = 0.21   # memory loss\n",
    "beta = 0.31    # intensity of choice\n",
    "h = 0.31       # relative strength of the normative component\n",
    "w_i = 3.2      # weights\n",
    "w_c = 1\n",
    "w_0 = 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:12:26.095053Z",
     "start_time": "2019-08-31T14:12:26.074035Z"
    }
   },
   "outputs": [],
   "source": [
    "def getNeighbours(N,row,col):\n",
    "    # return contains neighbours in order [Up, Right, Down, Left]\n",
    "    if row == 0:\n",
    "        if col == 0:\n",
    "            return [(N-1, col), (row, col+1), (row+1, col), (row, N-1)]\n",
    "        elif col == N-1:\n",
    "            return [(N-1, col), (row, 0), (row+1, col), (row, col-1)]\n",
    "        else:\n",
    "            return [(N-1, col), (row, col+1), (row+1, col), (row, col-1)]\n",
    "    elif row == N-1:\n",
    "        if col == 0:\n",
    "            return [(row-1, col), (row, col+1), (0, col), (row, N-1)]\n",
    "        elif col == N-1:\n",
    "            return [(row-1, col), (row, 0), (0, col), (row, col-1)]\n",
    "        else:\n",
    "            return [(row-1, col), (row, col+1), (0, col), (row, col-1)]\n",
    "    else: \n",
    "        return [(row-1, col), (row, col+1), (row+1, col), (row, col-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:12:26.115074Z",
     "start_time": "2019-08-31T14:12:26.107065Z"
    }
   },
   "outputs": [],
   "source": [
    "def getObservedCooperation(neighbours, A):\n",
    "    count = 0\n",
    "    for (ni,nj) in neighbours:\n",
    "        if A[ni*25+nj] == 0:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:12:26.125081Z",
     "start_time": "2019-08-31T14:12:26.117074Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeIndividualDrive(neighbours, A):\n",
    "    sum_diff = 0.0\n",
    "    for (ni,nj) in neighbours:\n",
    "        rew_C = payoffs[0][A[ni*25+nj]]\n",
    "        rew_D = payoffs[1][A[ni*25+nj]]\n",
    "        sum_diff += (rew_C - rew_D)\n",
    "    return sum_diff / 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(i,j, m, A_tm1, dN, dI, D_tp1, P_tp1):\n",
    "    # get neighbours of agent at position (i,j)\n",
    "    neighbours = getNeighbours(25, i, j) \n",
    "    # ct = 1 if agent cooperated, else 0\n",
    "    ct = 1 if A_tm1[i * m + j] == 0 else 0\n",
    "    # get previous neighbour cooperation count\n",
    "    Ot = getObservedCooperation(neighbours, A_tm1)\n",
    "    # get previous D\n",
    "    Dt = D_tp1[i * m + j]\n",
    "    # compute dN\n",
    "    dNt = w_c * (2 * ct - 1) + w_0 * Ot + w_i * ct * Ot\n",
    "    # compute dI\n",
    "    dIt = computeIndividualDrive(neighbours, A_tm1)\n",
    "    # compute new D_tp1\n",
    "    Dtp1 = (1.0 - alpha) * Dt + dIt + h * dNt\n",
    "    # compute cooperation probability\n",
    "    Ptp1 = 1.0 / (1.0 + math.exp(-beta * Dtp1))\n",
    "    # select action and update variables\n",
    "    A_tm1[i * m + j] = 0 if np.random.random() <= Ptp1 else 1 \n",
    "    dN[i * m + j] = dNt\n",
    "    dI[i * m + j] = dIt\n",
    "    D_tp1[i * m + j] = Dtp1\n",
    "    P_tp1[i * m + j] = Ptp1 \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Lattice Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:12:32.145663Z",
     "start_time": "2019-08-31T14:12:26.126082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Containers for parameters of the game            \n",
    "A_tm1 = np.zeros(N, dtype=int)        # array of actions for the N players over the n rounds\n",
    "dI_stat = np.zeros((N,n))                      # array to store the individual drive for each player\n",
    "dN_stat = np.zeros((N,n))                      # array to store the norm salience for each player\n",
    "D_tp1 = np.multiply(D_0, np.ones(N))  # array to store the drive, initialised to D_0\n",
    "P_tp1_stat = np.zeros(N)                   # array to store the cooperation probability for each player\n",
    "cooperation_stat = np.zeros(n)             # counter for the cooperation over time\n",
    "    \n",
    "for t in range(n):\n",
    "    if t == 0:\n",
    "        # select action for each agent\n",
    "        for i in range(25):\n",
    "            for j in range(25):\n",
    "                A_tm1[i*25+j] = 0 if np.random.random() <= 0.6 else 1                               \n",
    "        # count cooperations\n",
    "        cooperation_stat[t] = (N - sum(A_tm1))/N\n",
    "    else:\n",
    "        # update parameters\n",
    "        for i in range(25):\n",
    "            for j in range(25):\n",
    "                # agent at position (i,j) plays\n",
    "                step(i,j, 25, A_tm1, dN_stat[:, t-1], dI_stat[:, t-1], D_tp1, P_tp1_stat)\n",
    "        # count cooperation\n",
    "        cooperation_stat[t] = (N - sum(A_tm1))/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic lattice simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for parameters of the game            \n",
    "A_tm1 = np.zeros(N, dtype=int)            # array of actions for the N players over the n round\n",
    "dI_dyn = np.zeros((N,n))                      # array to store the individual drive for each player\n",
    "dN_dyn = np.zeros((N,n))                      # array to store the norm salience for each player\n",
    "D_tp1 = np.multiply(D_0, np.ones(N))      # array to store the drive, initialised to D_0\n",
    "P_tp1_dyn = np.zeros(N)                   # array to store the cooperation probability for each player\n",
    "cooperation_dyn = np.zeros(n)             # counter for the cooperation over time\n",
    "    \n",
    "for t in range(n):\n",
    "    if t == 0:\n",
    "        # select action for each agent\n",
    "        for i in range(25):\n",
    "            for j in range(25):\n",
    "                A_tm1[i*25+j] = 0 if np.random.random() <= 0.6 else 1                               \n",
    "        # count cooperations\n",
    "        cooperation_dyn[t] = (N - sum(A_tm1))/N\n",
    "    else:\n",
    "        # randomly reposition agents\n",
    "        np.random.shuffle(A_tm1)\n",
    "        # update parameters\n",
    "        for i in range(25):\n",
    "            for j in range(25):\n",
    "                # agent at position (i,j) plays\n",
    "                step(i,j, 25, A_tm1, dN_dyn[:,t-1], dI_dyn[:, t-1], D_tp1, P_tp1_dyn)\n",
    "        # count cooperation\n",
    "        cooperation_dyn[t] = (N - sum(A_tm1))/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random network simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, b):\n",
    "    return 1 / (1 + math.e**(-b * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_net():\n",
    "    \"\"\"Generates a network with N nodes, each having k neighbours\n",
    "    \"\"\"\n",
    "    strats = [0, 1]\n",
    "    drive = np.full((N,), 0.6, dtype=np.float64)\n",
    "    pop = np.random.choice(strats, size=N, replace=True, p=[D_0, 1-D_0])\n",
    "    adjmat = np.empty((N,), dtype=object)\n",
    "    for i in range(adjmat.size):\n",
    "        adjmat[i] = []\n",
    "\n",
    "    for i, adj in np.ndenumerate(adjmat[:-1]):\n",
    "        if len(adj) < k:\n",
    "            sample = np.random.randint(i[0] + 1, N, size=k-len(adj))\n",
    "            # while the sample isn't valid, i.e. has duplicates or full neighbourhood's players, retry \n",
    "            while not len(sample) == len(set(sample)) and all(len(adjmat[other]) < k for other in sample):\n",
    "                sample = np.random.randint(i[0] + 1, N, size=k-len(adj))\n",
    "            adj.extend(sample)\n",
    "            for other in sample:\n",
    "                adjmat[other].append(i[0])\n",
    "\n",
    "    return pop, drive, adjmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_play(index, pop, adjmat, val=\"C\"):\n",
    "    \"\"\"Simulates the score of an agent at index if he were to play val in the current settings.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for other in adjmat[index]:\n",
    "        score += payoffs[val][pop[other]]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(pop, drive, adjmat, dI, dN, it):\n",
    "    updated_pop = np.empty_like(pop)\n",
    "    for i in range(pop.size):\n",
    "        Ot = sum([pop[j] == 0 for j in adjmat[i]])\n",
    "        ct = int(pop[i] == 0)\n",
    "        dnt = w_c * (2 * ct - 1) + w_0 * Ot + w_i * ct * Ot\n",
    "        dN[i, it] = dnt\n",
    "        dit = simulate_play(i, pop, adjmat, val=0) - simulate_play(i, pop, adjmat, val=1)\n",
    "        dit /= 4\n",
    "        dI[i, it] = dit\n",
    "        drive[i] = drive[i] * (1 - alpha) + dit + h * dnt\n",
    "        if np.random.random() < softmax(drive[i], beta):\n",
    "            updated_pop[i] = 0\n",
    "        else:\n",
    "            updated_pop[i] = 1\n",
    "    return updated_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooperation_rand = np.zeros(n)\n",
    "pop, drive, adjmat = generate_net()\n",
    "cooperation_rand[0] = (N - sum(pop))/N\n",
    "dI_rand = np.zeros((N,n))                      # array to store the individual drive for each player\n",
    "dN_rand = np.zeros((N,n))                      # array to store the norm salience for each player\n",
    "\n",
    "for i in range(pop.size):\n",
    "    Ot = sum([pop[j] == 0 for j in adjmat[i]])\n",
    "    ct = int(pop[i] == 0)\n",
    "    dnt = w_c * (2 * ct - 1) + w_0 * Ot + w_i * ct * Ot\n",
    "    dN_rand[i, 0] = dnt\n",
    "    dit = simulate_play(i, pop, adjmat, val=0) - simulate_play(i, pop, adjmat, val=1)\n",
    "    dit /= 4\n",
    "    dI_rand[i, 0] = dit\n",
    "    drive[i] = drive[i] * (1 - alpha) + dit + h * dnt\n",
    "    \n",
    "for t in range(1, n):\n",
    "    pop = update(pop, drive, adjmat, dI_rand, dN_rand, t)\n",
    "    cooperation_rand[t] = (N - sum(pop))/N\n",
    "\n",
    "P_tp1_rand = softmax(drive, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraction of agents that cooperated in each round of the game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:25:08.439828Z",
     "start_time": "2019-08-31T14:25:08.326724Z"
    }
   },
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(21,7))\n",
    "\n",
    "# plot the cooperation level\n",
    "time = np.arange(n)\n",
    "ax1.plot(time, cooperation_stat, marker = \"o\", label='Static')\n",
    "ax1.plot(time, cooperation_dyn, marker = \"D\", label='Dynamic')\n",
    "ax1.plot(time, cooperation_rand, marker = \"*\", label='Random')\n",
    "\n",
    "ax2.plot(time[0:52], cooperation_stat[0:52], marker = \"o\", label='Static')\n",
    "ax2.plot(time[0:52], cooperation_dyn[0:52], marker = \"D\", label='Dynamic')\n",
    "ax2.plot(time[0:52], cooperation_rand[0:52], marker = \"*\", label='Random')\n",
    "ax2.legend(fontsize='large')\n",
    "\n",
    "# add a big axis, hide frame\n",
    "fig.add_subplot(111, frameon=False)\n",
    "\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "plt.xlabel('Rounds', fontsize='x-large', labelpad=20)\n",
    "plt.ylabel('Fraction of cooperative acts', fontsize='x-large', labelpad=20)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('plots/cooperation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraction of agents that reached a certain probability of cooperation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myHist(bins, P):\n",
    "    ys = [0 for _ in bins]\n",
    "    for i, val in enumerate(bins):\n",
    "        for p in P:\n",
    "            if p >= val - 0.05 and p < val + 0.05:\n",
    "                ys[i] += 1\n",
    "    res = [float(ysi)/N for ysi in ys]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bar heights\n",
    "xs = [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "mu = [2*x*((1-x)**3) for x in xs]\n",
    "bars1 = myHist(xs, P_tp1_stat)\n",
    "bars2 = myHist(xs, P_tp1_dyn)\n",
    "bars3 = myHist(xs, P_tp1_rand)\n",
    "\n",
    "# Set width of bar\n",
    "barWidth = 0.25\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(xs))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "# Make the plot\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "ax.bar(r1, bars1, width=barWidth, edgecolor='white', label='Static')\n",
    "ax.bar(r2, bars2, width=barWidth, edgecolor='white', label='Dynamic')\n",
    "ax.bar(r3, bars3, width=barWidth, edgecolor='white', label='Random')\n",
    "ax.plot(r1, mu, c='k')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Probability of cooperation', fontsize='large')\n",
    "plt.ylabel('Fraction of players', fontsize='large')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], xs)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/prob_cooperation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability for a generic agent to cooperate after she cooperated or after she defected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationary state: Probability of agents who reached a given probability of cooperation, a certain individual drive and a given normative drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotStationaryState(P, dI, dN, filename):\n",
    "    # create figure\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, sharey= True, figsize=(21,7))\n",
    "\n",
    "    # plot the cooperation level\n",
    "    bins = [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    bars = myHist(bins, P)    \n",
    "    ax1.bar(np.arange(len(bins)), bars, width = 0.5, color='#0504aa',alpha=0.7)\n",
    "    ax1.set_xlabel('Probability of cooperation', fontsize='large')\n",
    "    ax1.set_ylabel('Fraction of players', fontsize='large')\n",
    "    ax1.set_ylim(0,1)\n",
    "    \n",
    "    # plot the individual drive\n",
    "    hist,bin_edges = np.histogram(dI[:,52], bins = 5)\n",
    "    ax2.bar(bin_edges[:-1], np.divide(hist,N), width = 0.5, color='#0504aa',alpha=0.7)\n",
    "    ax2.set_xlabel('Individual drive', fontsize='large')\n",
    "    ax2.set_ylabel('Fraction of players', fontsize='large')\n",
    "    ax2.set_xlim(-16,0)\n",
    "    \n",
    "    # plot the normative drive\n",
    "    hist,bin_edges = np.histogram(dN[:,52], bins = 5)\n",
    "    ax3.bar(bin_edges[:-1], np.divide(hist,N), width = 0.5, color='#0504aa',alpha=0.7)\n",
    "    ax3.set_xlabel('Normative drive', fontsize='large')\n",
    "    ax3.set_ylabel('Fraction of players', fontsize='large')\n",
    "    ax3.set_xlim(-5,30)\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Static lattice ***\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'myHist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-055f73dcaad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot for static lattice treatment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*** Static lattice ***'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplotStationaryState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_tp1_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdI_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdN_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plots/stationary_static.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plot for dynamic lattice treatment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f7698b9ff146>\u001b[0m in \u001b[0;36mplotStationaryState\u001b[0;34m(P, dI, dN, filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# plot the cooperation level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#0504aa'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Probability of cooperation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myHist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1512x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for static lattice treatment\n",
    "print('*** Static lattice ***')\n",
    "plotStationaryState(P_tp1_stat, dI_stat, dN_stat, 'plots/stationary_static.png')\n",
    "\n",
    "# plot for dynamic lattice treatment\n",
    "print('*** Dynamic lattice ***')\n",
    "plotStationaryState(P_tp1_dyn, dI_dyn, dN_dyn, 'plots/stationary_dyn.png')\n",
    "\n",
    "# plot for random network treatment\n",
    "print('*** Random network ***')\n",
    "plotStationaryState(P_tp1_rand, dI_rand, dN_rand, 'plots/stationary_rand.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
